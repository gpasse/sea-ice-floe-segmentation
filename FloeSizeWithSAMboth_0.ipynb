{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Phase 0: Sea Ice Image Segmentation with Segment Anything Model (SAM)*\n",
    "***\n",
    "Meta AI recently released the Segment Anything Model (SAM), which is a promptable segmentation system with zero-shot generalization to unfamiliar objects and images, without need for additional training.\n",
    "\n",
    "Here, we generate masks for a sample random of images, previously manually segmented for comparison, using both `SamAutomaticMaskGenerator` with default settings and `Sam Predictor` with seeds acquired from pre-processing during GVF application.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup and SAM initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Package  | Purpose  |\n",
    "| -------- | -------- |\n",
    "| `cv2`        | Open the image |\n",
    "| `matplotlib` | Plot figures |\n",
    "| `numpy`      | Manage arrays |\n",
    "| `torch`      | Manage input seeds into SAM |\n",
    "| `scipy` | Save output in a MATLAB format |\n",
    "| `segment_anything` | SAM |\n",
    "| `skimage` | Clean and post processing binary masks |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.io import savemat\n",
    "from segment_anything import SamAutomaticMaskGenerator, SamPredictor, sam_model_registry\n",
    "from skimage import measure, morphology, segmentation\n",
    "\n",
    "\n",
    "def circular(area, perimeter):\n",
    "    return (4 * np.pi * area) / perimeter**2\n",
    "\n",
    "\n",
    "# Function to read 1-D text file saved from MATLAB and convert to tensor\n",
    "def read_tensor(file_path, device):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = file.read().split()\n",
    "    data = list(map(float, data))\n",
    "    return torch.tensor(data, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SAM model can be loaded with 3 different encoders: ViT-B, ViT-L, and ViT-H. Set the path below to the SAM checkpoint.\n",
    "\n",
    "To run automatic mask generation, provide a SAM model to the `SamAutomaticMaskGenerator` class. Masks for the entire image can be generated by sampling a large number of prompts over an image.\n",
    "\n",
    "To run prediction given prompts that indicate the desired object, provide a SAM model to `SamPredictor` class. The model first converts the image into an image embedding that allows high quality masks to be efficiently produced from point and box prompts, as well as masks from the previous iteration of prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
    "\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "device = \"cpu\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayOfCruise = \"2022-07-23\"\n",
    "outputManual_path = os.path.join(\n",
    "    \"/Users/giuliopasserotti/Documents/Pyth.D/seaice_fsd_w_GVF/manual_fsd_pixelmator/output_left_\"\n",
    "    + dayOfCruise,\n",
    ")\n",
    "seedDiffuse_path = os.path.join(\n",
    "    \"/Users/giuliopasserotti/Documents/Pyth.D/seaice_fsd_w_GVF/output_left_\"\n",
    "    + dayOfCruise,\n",
    "    \"tmp\",\n",
    ")\n",
    "\n",
    "outputManualCropped_files = sorted(\n",
    "    glob.glob(os.path.join(outputManual_path, \"*croppedImage.png\"))\n",
    ")\n",
    "\n",
    "SAMsave_path = os.path.join(\n",
    "    \"/Users/giuliopasserotti/Documents/Pyth.D/seaice_fsd_w_GVF/manual_fsd_pixelmator/output_left_\"\n",
    "    + dayOfCruise\n",
    "    + \"_SAM\",\n",
    "    \"tmp\",\n",
    ")\n",
    "\n",
    "SAMpredsave_path = os.path.join(\n",
    "    \"/Users/giuliopasserotti/Documents/Pyth.D/seaice_fsd_w_GVF/manual_fsd_pixelmator/output_left_\"\n",
    "    + dayOfCruise\n",
    "    + \"_SAMpred\",\n",
    "    \"tmp\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic mask generation\n",
    "\n",
    "To generate masks, just run `generate` on an image. Mask generation returns a list over masks, where each mask is a dictionary containing various data about the mask. These keys are:\n",
    "* `segmentation` : the mask\n",
    "* `area` : the area of the mask in pixels\n",
    "* `bbox` : the boundary box of the mask in XYWH format\n",
    "* `predicted_iou` : the model's own prediction for the quality of the mask\n",
    "* `point_coords` : the sampled input point that generated this mask\n",
    "* `stability_score` : an additional measure of mask quality\n",
    "* `crop_box` : the crop of the image used to generate this mask in XYWH format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/2qsjmmg14wb09q4qz49pdb580000gn/T/ipykernel_30526/3057965229.py:14: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return (4 * np.pi * area) / perimeter**2\n"
     ]
    }
   ],
   "source": [
    "for file_path in outputManualCropped_files:\n",
    "    base_name = os.path.basename(file_path)[:18]\n",
    "\n",
    "    croppedImage_path = os.path.join(seedDiffuse_path, base_name + \"croppedImage.png\")\n",
    "    croppedImage = cv2.imread(croppedImage_path)\n",
    "    croppedImage = cv2.cvtColor(croppedImage, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    diffuseImage_path = os.path.join(seedDiffuse_path, base_name + \"diffuseImage.png\")\n",
    "    diffuseImage = cv2.imread(diffuseImage_path)\n",
    "    diffuseImage = cv2.cvtColor(diffuseImage, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    blackMask = np.all(croppedImage == [0, 0, 0], axis=2)\n",
    "    AggrSAM_masks = np.zeros_like(blackMask)\n",
    "    Allcoordinates = []\n",
    "    # AllperimPixelList = []\n",
    "\n",
    "    masks = mask_generator.generate(diffuseImage)\n",
    "    masks_binary = [mask[\"segmentation\"] for mask in masks]\n",
    "\n",
    "    for SAM_mask in masks_binary:\n",
    "        SAM_mask[blackMask] = True\n",
    "\n",
    "        bclearSAM = segmentation.clear_border(SAM_mask, buffer_size=1)\n",
    "\n",
    "        se = morphology.disk(2)\n",
    "        erodebclearSAM = morphology.binary_erosion(bclearSAM, se)\n",
    "\n",
    "        labelerodebclearSAM = measure.label(erodebclearSAM, connectivity=2)\n",
    "        regions = measure.regionprops(labelerodebclearSAM)\n",
    "\n",
    "        circularity = np.array(\n",
    "            [circular(prop.area, prop.perimeter) for prop in regions]\n",
    "        )\n",
    "        circularity = np.round(circularity, 2)\n",
    "        eccentricity = np.array([prop.eccentricity for prop in regions])\n",
    "        eccentricity = np.round(eccentricity, 2)\n",
    "        coordinates = [prop.coords for prop in regions]\n",
    "\n",
    "        noFloeIdx = np.where((circularity > 1) | ~np.isfinite(circularity))[0]\n",
    "        noFloeBW = np.isin(\n",
    "            labelerodebclearSAM, noFloeIdx + 1\n",
    "        )  # Add 1 because skimage labels start from 1\n",
    "\n",
    "        cleanSAM_mask = np.copy(erodebclearSAM)\n",
    "        cleanSAM_mask[noFloeBW] = False\n",
    "\n",
    "        circularity = np.delete(circularity, noFloeIdx)\n",
    "        eccentricity = np.delete(eccentricity, noFloeIdx)\n",
    "        coordinates = [\n",
    "            coordinates[i] for i in range(len(coordinates)) if i not in set(noFloeIdx)\n",
    "        ]\n",
    "\n",
    "        lineFloeIdx = np.where(eccentricity >= 0.9)[0]\n",
    "        labelcleanSAM = measure.label(cleanSAM_mask, connectivity=2)\n",
    "        lineFloeBW = np.isin(\n",
    "            labelcleanSAM, lineFloeIdx + 1\n",
    "        )  # Add 1 because skimage labels start from 1\n",
    "\n",
    "        cleanSAM_mask[lineFloeBW] = False\n",
    "\n",
    "        circularity = np.delete(circularity, lineFloeIdx)\n",
    "        eccentricity = np.delete(eccentricity, lineFloeIdx)\n",
    "        coordinates = [\n",
    "            coordinates[i] for i in range(len(coordinates)) if i not in set(lineFloeIdx)\n",
    "        ]\n",
    "\n",
    "        AggrSAM_masks[cleanSAM_mask] = True\n",
    "        Allcoordinates.append(coordinates)\n",
    "        # perimPixelList = measure.find_contours(cleanSAM_mask)\n",
    "        # AllperimPixelList.append(perimPixelList)\n",
    "\n",
    "    AllcoordinatesSAM_masks = [\n",
    "        coo for coords in Allcoordinates if coords for coo in coords\n",
    "    ]\n",
    "    AllcoordinatesSAM_masks = np.array(AllcoordinatesSAM_masks, dtype=object)\n",
    "    AllcoordinatesSAMmasks_path = os.path.join(\n",
    "        SAMsave_path, base_name + \"AllcoordinatesSAM_masks.mat\"\n",
    "    )\n",
    "    savemat(\n",
    "        AllcoordinatesSAMmasks_path,\n",
    "        {\"AllcoordinatesSAM_masks\": AllcoordinatesSAM_masks},\n",
    "    )\n",
    "\n",
    "    AggrSAMmasks_path = os.path.join(SAMsave_path, base_name + \"AggrSAM_masks.png\")\n",
    "    cv2.imwrite(AggrSAMmasks_path, np.uint8(AggrSAM_masks * 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Function  | Purpose  |\n",
    "| -------- | -------- |\n",
    "| `segmentation`        | Clear floes connected to the image borders |\n",
    "| `morphology` | Binary erosion of an amount equal to disk(2) |\n",
    "| `measure`      | Regionprops to filter based on circularity, eccentricity and retrieve floes coords |\n",
    "\n",
    "\n",
    "Note that circularity and eccentricity give lower results compared to MATLAB. In addition `measure.find_contours` finds different perimeter pixel list compared to `bwboundaries` on MATLAB. Reason why I need to save directly the coords that form the floes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate segmentation with point prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/2qsjmmg14wb09q4qz49pdb580000gn/T/ipykernel_29230/3057965229.py:14: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return (4 * np.pi * area) / perimeter**2\n"
     ]
    }
   ],
   "source": [
    "for file_path in outputManualCropped_files:\n",
    "    base_name = os.path.basename(file_path)[:18]\n",
    "\n",
    "    croppedImage_path = os.path.join(seedDiffuse_path, base_name + \"croppedImage.png\")\n",
    "    croppedImage = cv2.imread(croppedImage_path)\n",
    "    croppedImage = cv2.cvtColor(croppedImage, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    diffuseImage_path = os.path.join(seedDiffuse_path, base_name + \"diffuseImage.png\")\n",
    "    diffuseImage = cv2.imread(diffuseImage_path)\n",
    "    diffuseImage = cv2.cvtColor(diffuseImage, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    seedX_path = os.path.join(seedDiffuse_path, base_name + \"roundXseeds.txt\")\n",
    "    seedY_path = os.path.join(seedDiffuse_path, base_name + \"roundYseeds.txt\")\n",
    "    seedX = read_tensor(seedX_path, predictor.device)\n",
    "    seedY = read_tensor(seedY_path, predictor.device)\n",
    "\n",
    "    input_point = torch.stack([seedX, seedY], dim=1).unsqueeze(1)\n",
    "    input_label = torch.ones((input_point.shape[0], 1), device=predictor.device)\n",
    "\n",
    "    blackMask = np.all(croppedImage == [0, 0, 0], axis=2)\n",
    "    AggrSAMpred_masks = np.zeros_like(blackMask)\n",
    "    Allcoordinates = []\n",
    "    # AllperimPixelList = []\n",
    "\n",
    "    predictor.set_image(diffuseImage)\n",
    "    transformed_points = predictor.transform.apply_coords_torch(\n",
    "        input_point, diffuseImage.shape[:2]\n",
    "    )\n",
    "\n",
    "    masks, _, _ = predictor.predict_torch(\n",
    "        point_coords=transformed_points,\n",
    "        point_labels=input_label,\n",
    "        boxes=None,\n",
    "        multimask_output=False,\n",
    "    )\n",
    "    masks_binary = masks.clone().squeeze().numpy()\n",
    "\n",
    "    for SAMpred_mask in masks_binary:\n",
    "        SAMpred_mask[blackMask] = True\n",
    "\n",
    "        bclearSAMpred = segmentation.clear_border(SAMpred_mask, buffer_size=1)\n",
    "\n",
    "        se = morphology.disk(2)\n",
    "        erodebclearSAMpred = morphology.binary_erosion(bclearSAMpred, se)\n",
    "\n",
    "        labelerodebclearSAMpred = measure.label(erodebclearSAMpred, connectivity=2)\n",
    "        regions = measure.regionprops(labelerodebclearSAMpred)\n",
    "\n",
    "        circularity = np.array(\n",
    "            [circular(prop.area, prop.perimeter) for prop in regions]\n",
    "        )\n",
    "        circularity = np.round(circularity, 2)\n",
    "        eccentricity = np.array([prop.eccentricity for prop in regions])\n",
    "        eccentricity = np.round(eccentricity, 2)\n",
    "        coordinates = [prop.coords for prop in regions]\n",
    "\n",
    "        noFloeIdx = np.where((circularity > 1) | ~np.isfinite(circularity))[0]\n",
    "        noFloeBW = np.isin(\n",
    "            labelerodebclearSAMpred, noFloeIdx + 1\n",
    "        )  # Add 1 because skimage labels start from 1\n",
    "\n",
    "        cleanSAMpred_mask = np.copy(erodebclearSAMpred)\n",
    "        cleanSAMpred_mask[noFloeBW] = False\n",
    "\n",
    "        circularity = np.delete(circularity, noFloeIdx)\n",
    "        eccentricity = np.delete(eccentricity, noFloeIdx)\n",
    "        coordinates = [\n",
    "            coordinates[i] for i in range(len(coordinates)) if i not in set(noFloeIdx)\n",
    "        ]\n",
    "\n",
    "        lineFloeIdx = np.where(eccentricity >= 0.9)[0]\n",
    "        labelcleanSAMpred = measure.label(cleanSAMpred_mask, connectivity=2)\n",
    "        lineFloeBW = np.isin(\n",
    "            labelcleanSAMpred, lineFloeIdx + 1\n",
    "        )  # Add 1 because skimage labels start from 1\n",
    "\n",
    "        cleanSAMpred_mask[lineFloeBW] = False\n",
    "\n",
    "        circularity = np.delete(circularity, lineFloeIdx)\n",
    "        eccentricity = np.delete(eccentricity, lineFloeIdx)\n",
    "        coordinates = [\n",
    "            coordinates[i] for i in range(len(coordinates)) if i not in set(lineFloeIdx)\n",
    "        ]\n",
    "\n",
    "        AggrSAMpred_masks[cleanSAMpred_mask] = True\n",
    "        Allcoordinates.append(coordinates)\n",
    "        # perimPixelList = measure.find_contours(cleanSAM_mask)\n",
    "        # AllperimPixelList.append(perimPixelList)\n",
    "\n",
    "    AllcoordinatesSAMpred_masks = [\n",
    "        coo for coords in Allcoordinates if coords for coo in coords\n",
    "    ]\n",
    "    AllcoordinatesSAMpred_masks = np.array(AllcoordinatesSAMpred_masks, dtype=object)\n",
    "    AllcoordinatesSAMpredmasks_path = os.path.join(\n",
    "        SAMpredsave_path, base_name + \"AllcoordinatesSAMpred_masks.mat\"\n",
    "    )\n",
    "    savemat(\n",
    "        AllcoordinatesSAMpredmasks_path,\n",
    "        {\"AllcoordinatesSAMpred_masks\": AllcoordinatesSAMpred_masks},\n",
    "    )\n",
    "\n",
    "    AggrSAMpredmasks_path = os.path.join(\n",
    "        SAMpredsave_path, base_name + \"AggrSAMpred_masks.png\"\n",
    "    )\n",
    "    cv2.imwrite(AggrSAMpredmasks_path, np.uint8(AggrSAMpred_masks * 255))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coursera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
